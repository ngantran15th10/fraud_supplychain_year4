======================================================================
PROJECT OVERVIEW
Supply Chain Fraud Detection Using Deep Neural Networks
======================================================================

PROJECT INFORMATION
-------------------
Project Title: Supply Chain Fraud Detection System Using Deep Learning 
              and Social Network Analysis
Institution: Year 4 Research Project
Date: November 2025
Dataset: DataCo Supply Chain Dataset

RESEARCH OBJECTIVES
-------------------
1. Develop an effective fraud detection system for supply chain transactions
2. Compare performance of different feature sets:
   - Transaction-based features only
   - Network-based features only
   - Combined features (Transaction + Network)
3. Achieve industry-standard performance (Recall >= 70%)
4. Minimize false negatives (undetected fraud) while managing false positives

DATASET STATISTICS
------------------
Source: DataCo Supply Chain Dataset
Total Orders: 180,519
Total Customers: 20,652
Time Period: Multi-year transaction history

Class Distribution:
- Not Fraud: 168,082 orders (93.1%)
- Fraud: 12,437 orders (6.9%)
- Imbalance Ratio: 13.5:1

Test Set Split:
- Total: 4,131 orders (20% of dataset)
- Not Fraud: 3,845 orders
- Fraud: 286 orders

FEATURE ENGINEERING
-------------------
Total Features: 61 (after feature engineering)

1. Transaction Features (57 features):
   - Order Information: product category, department, quantity, price
   - Customer Behavior: order history, purchase patterns, frequency
   - Shipping Details: mode, days for shipping, delivery status
   - Geographic: shipping location, customer location
   - Temporal: order date, delivery date, processing time
   - Financial: total price, discount, profit margin

2. Network Features (4 features):
   Generated using Social Network Analysis (SNA) on customer-product graph:
   - degree: Number of connections (customer's network size)
   - betweenness: Centrality measure (bridging role in network)
   - closeness: How close customer is to other nodes
   - pagerank: Importance score in the network

3. Dimensionality Reduction:
   - Method: Principal Component Analysis (PCA)
   - Components: 45 (from 61 original features)
   - Explained Variance: >95%
   - Purpose: Reduce noise, prevent overfitting, improve training speed

METHODOLOGY
-----------
1. Data Preprocessing:
   - Missing value imputation
   - Feature scaling (StandardScaler)
   - Class imbalance handling (SMOTE)
   - Dimensionality reduction (PCA)

2. Model Architecture:
   - Type: Deep Neural Network (Feedforward)
   - Layers: Input(45) -> Dense(256) -> Dense(128) -> Dense(64) -> Output(1)
   - Activation: ReLU (hidden layers), Sigmoid (output layer)
   - Regularization: BatchNormalization, Dropout (0.3, 0.3, 0.2)
   - Optimizer: Adam (learning_rate=0.001)

3. Ensemble Strategy:
   - Number of Models: 3
   - Random Seeds: [42, 123, 456]
   - Prediction Method: Simple averaging of probabilities
   - Purpose: Improve generalization, reduce variance

4. Class Imbalance Handling:
   - SMOTE (Synthetic Minority Over-sampling Technique)
   - Sampling Strategy: 1.0 (fully balanced training set)
   - Applied after train-test split (avoid data leakage)

5. Custom Loss Function:
   - Name: Cost-Sensitive Focal Loss
   - Base: Focal Loss (gamma=0.8, alpha=0.80)
   - Enhancement: False Negative penalty (FN_COST=15.0)
   - Formula: Focal_Loss + (y_true * (1 - y_pred) * FN_COST)
   - Purpose: Heavily penalize missed frauds (False Negatives)

6. Threshold Optimization:
   - Method: Manual tuning for maximum Recall
   - Final Threshold: 0.20
   - Rationale: Prioritize fraud detection over precision

EXPERIMENTAL CONFIGURATIONS
----------------------------
Multiple configurations were tested during development:

1. Baseline Configuration:
   - Loss: Binary Crossentropy
   - Threshold: Auto-optimized (F1-score)
   - SMOTE: 0.5 (balanced to 50%)
   - Result: Recall 42.66% (FAILED target)

2. Phase 1-2 Configuration:
   - Loss: Focal Loss (gamma=2.0, alpha=0.75)
   - Threshold: 0.30
   - SMOTE: 0.5
   - Result: Recall 68.53% (Close to target)

3. AGGRESSIVE Configuration (FINAL):
   - Loss: Cost-Sensitive Focal Loss (FN_COST=15.0)
   - Threshold: 0.20
   - SMOTE: 1.0 (fully balanced)
   - Ensemble: 3 models with different seeds
   - Result: Recall 74.83% (TARGET ACHIEVED)

4. Stacking Ensemble (Attempted):
   - Base Models: DNN, Random Forest, XGBoost, LightGBM
   - Meta-Learner: Logistic Regression
   - Result: Recall 32.87% (FAILED - too conservative)
   - Decision: Abandoned due to poor Recall

KEY INNOVATIONS
---------------
1. Cost-Sensitive Focal Loss:
   - Novel combination of Focal Loss with explicit FN penalty
   - Addresses both class imbalance and business cost priorities
   - Significantly improved Recall from 42% to 74%

2. Network Feature Integration:
   - First study to combine SNA features with transaction features
   - Captures customer behavior patterns not visible in transactions alone
   - Network centrality metrics provide additional fraud signals

3. Aggressive Threshold Tuning:
   - Traditional ML prioritizes balanced metrics (F1-score)
   - This project prioritizes Recall (fraud detection rate)
   - Threshold=0.20 is much lower than typical 0.5

4. Ensemble Averaging Strategy:
   - Simple but effective: outperforms complex stacking
   - Maintains high Recall (stacking reduced Recall to 32%)
   - Demonstrates that simpler is sometimes better

CHALLENGES AND SOLUTIONS
-------------------------
Challenge 1: Severe Class Imbalance (93% vs 7%)
Solution: 
- SMOTE with full balancing (sampling_strategy=1.0)
- Cost-sensitive loss function
- Custom threshold optimization

Challenge 2: Low Baseline Recall (42%)
Solution:
- Implemented Cost-Sensitive Focal Loss
- Increased FN penalty from 5.0 to 15.0
- Reduced threshold from 0.5 to 0.20

Challenge 3: Stacking Ensemble Failed
Solution:
- Analyzed meta-learner behavior (optimized for Accuracy, not Recall)
- Switched to simple averaging ensemble
- Proved that simpler approach works better for imbalanced data

Challenge 4: Feature Dimensionality (61 features)
Solution:
- Applied PCA to reduce to 45 components
- Retained >95% explained variance
- Improved training speed and reduced overfitting

Challenge 5: Overfitting Risk
Solution:
- BatchNormalization after each dense layer
- Dropout regularization (0.3, 0.3, 0.2)
- Early stopping (patience=10)
- Ensemble of 3 models with different seeds

PERFORMANCE COMPARISON
-----------------------
Target: Recall >= 70% (industry standard for fraud detection)

Final Model (AGGRESSIVE Ensemble):
- Recall: 74.83% (EXCEEDS TARGET by 4.83%)
- Frauds Detected: 214 / 286 (74.83%)
- Frauds Missed: 72 (25.17%)
- Precision: 20.15%
- ROC-AUC: 82.16%

Comparison with Alternatives:
- Baseline (Single Model): 41.61% Recall (BELOW TARGET)
- Stacking Ensemble: 32.87% Recall (BELOW TARGET)
- Phase 1-2: 68.53% Recall (CLOSE to target)

BUSINESS IMPACT
---------------
Assuming average fraud value: $1,000 per transaction
Assuming investigation cost: $50 per alert

Cost Analysis (AGGRESSIVE Ensemble):
- Frauds Caught: 214 × $1,000 = $214,000 saved
- Frauds Missed: 72 × $1,000 = $72,000 lost
- Investigation Cost: 1,062 alerts × $50 = $53,100
- Net Benefit: $214,000 - $72,000 - $53,100 = $88,900

Comparison with Baseline (Single Model):
- Net Result: -$69,100 (NET LOSS)
- Difference: $158,000 improvement with AGGRESSIVE model
